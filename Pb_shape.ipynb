{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc481f-698e-4671-b543-444d886c9c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.integrate\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "legfont=16\n",
    "plt.rc(\"xtick\", labelsize=legfont)\n",
    "plt.rc(\"ytick\", labelsize=legfont)\n",
    "\n",
    "FMGEV=5.068\n",
    "\n",
    "def WoodsSaxon(r, R, a):\n",
    "    ''' r distance from center\n",
    "        R: nuclear radius\n",
    "        '''\n",
    "    return 1/(1 + np.exp((r-R)/a) )\n",
    "\n",
    "def TA(b, R, a):\n",
    "    f = lambda z: WoodsSaxon(np.sqrt(z**2+b**2), R, a)\n",
    "    \n",
    "    integrated = scipy.integrate.quad(f, -np.inf, np.inf)[0]\n",
    "    \n",
    "    norm = 3.0/(4.0 * np.pi * R**3) * 1.0/(1.0 + ( np.pi * a/R)**2)\n",
    "    \n",
    "    return norm*integrated\n",
    "\n",
    "scipy.integrate.quad(lambda b: 2.0*np.pi*b*TA(b, 6*FMGEV, 0.5*FMGEV), 0, np.inf)\n",
    "\n",
    "TA(1,6*FMGEV, 0.5*FMGEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35fe93-23e4-48dc-af4a-5a2f4721edf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ComputeAverage(dirname, maxconf=100):\n",
    "    data=[]\n",
    "    for i in range(1,maxconf):\n",
    "        d = np.loadtxt(dirname + \"Run\" + str(i) + \".txt\")\n",
    "        \n",
    "        # note the below function will not work for dataframe as the two lines on top of every Run${i}.txt file\\\n",
    "        # makes it impossible to slice. Use d.shape to see that the # of columns is 1, and hence no slicing in column.\n",
    "        if np.sum(d[:,2])<1e-10:\n",
    "            print(\"Only zeros in file \" + i)\n",
    "            continue\n",
    "        \n",
    "        #print (d.shape)\n",
    "        data.append(d)\n",
    "        \n",
    "    err = scipy.stats.sem(data, axis=0)\n",
    "    \n",
    "    data = np.mean(data, axis=0)\n",
    "    \n",
    "    data = pd.DataFrame(data, columns=[\"b\",\"N\",\"averageN\"])\n",
    "    \n",
    "    # noramlize\n",
    "    interp = scipy.interpolate.interp1d(data[\"b\"],data[\"averageN\"], bounds_error=False, fill_value=0)\n",
    "    norm = scipy.integrate.quad(lambda b: 2.0*np.pi*b*interp(b), 0, np.inf)[0]\n",
    "    data[\"averageN\"]/=norm\n",
    "    data[\"err\"]=err[:,2]/norm\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "for Y in [4.8]:\n",
    "    for r in [0.1]:\n",
    "        data=ComputeAverage(f'Fluctuatingx0_roots200/Y{Y}r{r}/', maxconf=150)\n",
    "    \n",
    "        bvals=np.linspace(-50,50)\n",
    "        popt, pcov = scipy.optimize.curve_fit( np.vectorize(TA), data[\"b\"], data[\"averageN\"], p0=[7*FMGEV,0.5] )\n",
    "\n",
    "        plt.plot(data[\"b\"]/FMGEV, data[\"averageN\"], label=\"IPGlasma Pb\", color=\"black\")\n",
    "        plt.fill_between(data[\"b\"]/FMGEV, data[\"averageN\"]-data[\"err\"], data[\"averageN\"]+data[\"err\"],color=\"black\",alpha=0.2)\n",
    "        plt.plot(bvals/FMGEV, np.vectorize(TA)(bvals, *popt), linestyle=\"dashed\", \n",
    "                 label=\"WS fit, $R=\" + str(round(popt[0]/FMGEV,3)) + r\"\\,\\mathrm{fm}, a=\"+str(round(popt[1]/FMGEV,3)) + r\"\\,\\mathrm{fm}$\")\n",
    "        plt.plot(bvals/FMGEV, np.vectorize(TA)(bvals,7*FMGEV, 0.546*FMGEV), linestyle=\"dashed\", \n",
    "                 label=\"WS fit--our guess R = 7 and a = 0.546\" )\n",
    "        \n",
    "        plt.xlabel(\"b [fm]\", fontsize=14)\n",
    "        plt.ylabel(r\"$T_A(b),$\" + f'r={r}' + r\"$\\,\\mathrm{fm}$\", fontsize=14)\n",
    "        leg = plt.legend(loc=\"lower center\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'Fluctuatingx0_roots200/PLOTS/Y{Y}r{r}.pdf')\n",
    "        plt.clf()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "514b4f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-45.612 , -44.5984, -43.5848, -42.5712, -41.5576, -40.544 ,\n",
       "       -39.5304, -38.5168, -37.5032, -36.4896, -35.476 , -34.4624,\n",
       "       -33.4488, -32.4352, -31.4216, -30.408 , -29.3944, -28.3808,\n",
       "       -27.3672, -26.3536, -25.34  , -24.3264, -23.3128, -22.2992,\n",
       "       -21.2856, -20.272 , -19.2584, -18.2448, -17.2312, -16.2176,\n",
       "       -15.204 , -14.1904, -13.1768, -12.1632, -11.1496, -10.136 ,\n",
       "        -9.1224,  -8.1088,  -7.0952,  -6.0816,  -5.068 ,  -4.0544,\n",
       "        -3.0408,  -2.0272,  -1.0136,   0.    ,   1.0136,   2.0272,\n",
       "         3.0408,   4.0544,   5.068 ,   6.0816,   7.0952,   8.1088,\n",
       "         9.1224,  10.136 ,  11.1496,  12.1632,  13.1768,  14.1904,\n",
       "        15.204 ,  16.2176,  17.2312,  18.2448,  19.2584,  20.272 ,\n",
       "        21.2856,  22.2992,  23.3128,  24.3264,  25.34  ,  26.3536,\n",
       "        27.3672,  28.3808,  29.3944,  30.408 ,  31.4216,  32.4352,\n",
       "        33.4488,  34.4624,  35.476 ,  36.4896,  37.5032,  38.5168,\n",
       "        39.5304,  40.544 ,  41.5576,  42.5712,  43.5848,  44.5984,\n",
       "        45.612 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "b=np.linspace(-45.612,45.612,91)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44674c39",
   "metadata": {},
   "source": [
    "### \"\"\"Checking angle dependence for Pb nucleus\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAverage(dirname, maxconf=100):\n",
    "    data=[]\n",
    "    for i in range(1,maxconf):\n",
    "        d = np.loadtxt(dirname + \"Run\" + str(i) + \".txt\")\n",
    "        \n",
    "        if np.sum(d[:,2])<1e-10:\n",
    "            print(\"Only zeros in file \" + i)\n",
    "            continue\n",
    "        \n",
    "        #print (d.shape)\n",
    "        data.append(d)\n",
    "        \n",
    "    err = scipy.stats.sem(data, axis=0)\n",
    "    \n",
    "    data = np.mean(data, axis=0)\n",
    "    \n",
    "    data = pd.DataFrame(data, columns=[\"b\",\"N\",\"averageN\"])\n",
    "    \n",
    "    # noramlize\n",
    "    interp = scipy.interpolate.interp1d(data[\"b\"],data[\"averageN\"], bounds_error=False, fill_value=0)\n",
    "    norm = scipy.integrate.quad(lambda b: 2.0*np.pi*b*interp(b), 0, np.inf)[0]\n",
    "    data[\"averageN\"]/=norm\n",
    "    data[\"err\"]=err[:,2]/norm\n",
    "    \n",
    "    return data\n",
    "\n",
    "r=0.3\n",
    "\n",
    "data=ComputeAverage(f'Fluctuatingx0_roots200/CHECK_ANGLE_DEP/r0.3Theta0/', maxconf=20)\n",
    "\n",
    "bvals=np.linspace(-50,50)\n",
    "\n",
    "popt, pcov = scipy.optimize.curve_fit( np.vectorize(TA), data[\"b\"], data[\"averageN\"], p0=[1*FMGEV,1.0] )\n",
    "\n",
    "plt.plot(data[\"b\"]/FMGEV, data[\"averageN\"], label=\"IPGlasma Pb\", color=\"black\")\n",
    "plt.fill_between(data[\"b\"]/FMGEV, data[\"averageN\"]-data[\"err\"], data[\"averageN\"]+data[\"err\"],color=\"black\",alpha=0.2)\n",
    "plt.plot(bvals/FMGEV, np.vectorize(TA)(bvals, *popt), linestyle=\"dashed\", \n",
    "         label=\"WS fit, $R=\" + str(round(popt[0]/FMGEV,3)) + r\"\\,\\mathrm{fm}, a=\"+str(round(popt[1]/FMGEV,3)) + r\"\\,\\mathrm{fm}$\")\n",
    "plt.xlabel(\"b [fm]\", fontsize=14)\n",
    "plt.ylabel(r\"$T_A(b),$\" + f'r={r}' + r\"$\\,\\mathrm{fm}$\", fontsize=14)\n",
    "leg = plt.legend(loc=\"lower center\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'Fluctuatingx0_roots200/CHECK_ANGLE_DEP/PLOTS/r0.3Theta0.pdf')\n",
    "plt.clf()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043461fe",
   "metadata": {},
   "source": [
    "## Violation of WOOD SAXON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb758767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.integrate\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "legfont=16\n",
    "plt.rc(\"xtick\", labelsize=legfont)\n",
    "plt.rc(\"ytick\", labelsize=legfont)\n",
    "\n",
    "FMGEV=5.068\n",
    "\n",
    "def WoodsSaxon(r, R, a):\n",
    "    ''' r distance from center\n",
    "        R: nuclear radius\n",
    "        '''\n",
    "    \n",
    "    return 1/(1 + np.exp((r-R)/a) )\n",
    "\n",
    "def TA(b, R, a):\n",
    "    f = lambda z: WoodsSaxon(np.sqrt(z**2+b**2), R, a)\n",
    "    \n",
    "    integrated = scipy.integrate.quad(f, -np.inf, np.inf)[0]\n",
    "    \n",
    "    norm = 3.0/(4.0 * np.pi * R**3) * 1.0/(1.0 + ( np.pi * a/R)**2)\n",
    "    \n",
    "    return norm*integrated\n",
    "\n",
    "scipy.integrate.quad(lambda b: 2.0*np.pi*b*TA(b, 6*FMGEV, 0.5*FMGEV), 0, np.inf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca906949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAverage(dirname, maxconf=100):\n",
    "    data=[]\n",
    "    for i in range(1,maxconf):\n",
    "        d = np.loadtxt(dirname + \"Run\" + str(i) + \".txt\")\n",
    "        \n",
    "        if np.sum(d[:,2])<1e-10:\n",
    "            print(\"Only zeros in file \" + i)\n",
    "            continue\n",
    "        \n",
    "        data.append(d)\n",
    "        \n",
    "    err = scipy.stats.sem(data, axis=0)\n",
    "    \n",
    "    data = np.mean(data, axis=0)\n",
    "    \n",
    "    data = pd.DataFrame(data, columns=[\"b\",\"N\",\"averageN\"])\n",
    "    \n",
    "    \"\"\" NORMALIZING IT HERE FOR GETTING RID OF V0 IN THE NUMERATOR\"\"\"\n",
    "    #### noramlize\n",
    "    interp = scipy.interpolate.interp1d(data[\"b\"],data[\"averageN\"], bounds_error=False, fill_value=0)\n",
    "    norm = scipy.integrate.quad(lambda b: 2.0*np.pi*b*interp(b), 0, np.inf)[0]\n",
    "    data[\"averageN\"]/=norm\n",
    "    data[\"err\"]=err[:,2]/norm\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\"\"\"SAVING THE NORMALIZED BESTFIT DATA FOR Y = 0 AND r = 0.1 fm\"\"\"\n",
    "Bestfit=ComputeAverage(f'Fluctuatingx0_roots200/Y0r0.1/', maxconf=150)\n",
    "\n",
    "popt, pcov = scipy.optimize.curve_fit(np.vectorize(TA), Bestfit[\"b\"], Bestfit[\"averageN\"], p0=[1*FMGEV,1.0] )\n",
    "Bestfit[\"averageN\"]=np.vectorize(TA)(Bestfit[\"b\"], *popt)\n",
    "Bestfit = Bestfit.drop(columns={\"N\", \"err\"})\n",
    "\n",
    "Bestfit.to_csv(f'Fluctuatingx0_roots200/BestfitY0r0.1.txt', sep=' ', index=False)\n",
    "\n",
    "WS_violate = []\n",
    "for Y in [0, 2.4, 4.8, 7.2, 9.6]:\n",
    "    for r in [0.05, 0.1]:\n",
    "        data=ComputeAverage(f'Fluctuatingx0_roots200/Y{Y}r{r}/', maxconf=150)\n",
    "        \n",
    "        \"\"\"NORMALISING FOR THE WOODSAXON VIOLATION\"\"\"\n",
    "        interp = scipy.interpolate.interp1d(data[\"b\"],abs(data[\"averageN\"]-Bestfit[\"averageN\"]), bounds_error=False, fill_value=0)\n",
    "        val = scipy.integrate.quad(lambda b: 2.0*np.pi*b*interp(b), 0, np.inf)[0]\n",
    "        WS_violate.append((Y,r,val))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664497fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkdata=ComputeAverage(f'Fluctuatingx0_roots200/Y9.6r0.1/', maxconf=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkdata.to_csv('Fluctuatingx0_roots200/Chky9.6r0.1avg.txt', sep=' ', index=False)\n",
    "Bestfit=pd.read_csv('Fluctuatingx0_roots200/BestfitY0r0.1.txt',  delimiter=' ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"checking the Violation for Y9.6r0.l case\"\"\"\n",
    "areaa = 0.0\n",
    "db=1.0136\n",
    "i=0\n",
    "for b in blist: #taking pi instead of 2 pi because data would be symmetric and hence in normalizing the WS part, integrated over 0 to infinity, and not on -infinity to infinity\n",
    "    areaa += np.pi * abs(chkdata.loc[i,\"b\"]) * db * abs(Bestfit.loc[i,\"averageN\"] - chkdata.loc[i,\"averageN\"])\n",
    "    i+=1\n",
    "print(areaa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
